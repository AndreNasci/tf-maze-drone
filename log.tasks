Registro das tasks completadas:

06/06:
    Hipótese: o desafio está muito complexo. O drone não
    está conseguindo chegar ao fim do labirinto vezes o
    suficiente para aprender com isso.
    ✔ Tornar tamanho do maze variável @done (6/6/2024, 11:10:40 AM)

    ✔ Testar treinamento com maze 5x5 @done (6/6/2024, 4:48:05 PM)
    ☐ Limpar código
    ✔ Melhorar readme e página github @done (6/6/2024, 11:58:43 AM)
    ✔ Pesquisar licença MIT @done (6/6/2024, 11:33:04 AM)
    ✔ Citar criador do gerador de labirintos @done (6/6/2024, 11:58:48 AM)
    ☐ Criar notebook de treinamento, com opção de continuar treinamento
    ☐ Traduzir comentários para o inglês

    Descobri uma falha na minha função is_stuck, que estava fornecendo 
    recompensas de forma errada.
    ✔ Corrigir função is_stuck() @done (6/6/2024, 4:47:08 PM)
    
    ☐ Checar métrica "Avg of Steps/Episode"

10/06:
    Hipótese:
        É possível que, no fim, o  algoritmo aprenda o algoritmo de 
        geração de labirintos

14/06:
    ✔ Aprender a criar novos observers @done (6/14/2024, 11:42:34 AM)
    ✔ Criar observer que verifica quantiadde de movimentos contra parede @done (6/19/2024, 3:00:02 PM)

    Insights Pokemon Video:
        - 

    ☐ Entender melhor processo de treinamento
        - Depois de quantos steps / episodes o modelo é treinado?
        - Com quais dados é treinado?
        - O quanto isso influencia?

    ☐ Mudar a cor do drone quando ele atingir a parede
    ☐ Tornar PATH independente da máquina


    criar uma função que roda o treinamento com base em alguns parâmetros e retorna apenas os resultados


        testar outros formatos de redes neurais, ver como elas se comportam
        particionar o treinamento em fases
            passar environment como listas 
            criar uma classe treinamento - instância possui atributos que dizem quais environments e quando eles devem ser acionados
            talvez criar um treinamnto inteligente (callback functions que dizem quando entrar o novo treinamento ou se não está convergindo)
            será que o próprio tf-agents não faz isso sozinho?

19/06:
    Maze sem paredes (aprender a perseguir o alvo)
    Adicionar paredes

    Como tornar o processo reproduzível?

    O que eu espero no final?
        Entendimento melhor de redes neurais
            o que é melhor? O que exatamente eu pretendo aprender?
        Projeto prático de IA (portfólio)

        Exercitar aprender algo por minha conta e executar

        Aprender sobre reinforcement learning
        Aprender documentação
        Exercitar versionamento
        Me envolver com comunidades de ML
        Projeto prático com Tensor Flow (portfólio)

20/06:

    branch para criar novos cenários de treinamento 
    alguma forma de manter log dos experimentos 

    remover my_metric do observer e inserir como um avaliador
    verificar se mode é o mesmo em train e eval
    verificar se muda após o  reset

    salvar agente para deploy e testes
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MazeDrone with TF Agents - 4000 Testing Trained Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 16:25:14.448416: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-15 16:25:14.708609: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-15 16:25:15.755032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-15 16:25:17.647259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "\n",
    "from resources import build_agent, TrainingSession\n",
    "import pandas as pd\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 1\n",
      "Mode set: 1\n",
      "Maze site set: 3x3\n",
      "Maze site set: 3x3\n",
      "WARNING:tensorflow:From /home/naski/Documents/dev/maze_drone_v02/maze-drone-v03/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "Rewards: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}\n",
      "WARNING:tensorflow:From /home/naski/Documents/dev/maze_drone_v02/maze-drone-v03/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_combination = 2 # combination 2\n",
    "min_run = 1\n",
    "max_run = 1\n",
    "\n",
    "\n",
    "num_iterations = 20_000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 64  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "#replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 100  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 100  # @param {type:\"integer\"}\n",
    "\n",
    "# Agent fully connected layer params \n",
    "fc_layer_params = (200,) \n",
    "\n",
    "# File's name\n",
    "description = \"2001\"\n",
    "\n",
    "maze_size = 3\n",
    "\n",
    "rewards = []\n",
    "rewards.append({\n",
    "    'destroyed': -10.,\n",
    "    'stuck': - 6.,\n",
    "    'reached': 10.,\n",
    "    'standard': -1.\n",
    "})\n",
    "rewards.append({\n",
    "    'destroyed': -10.,\n",
    "    'stuck': -11.,\n",
    "    'reached': 10.,\n",
    "    'standard': -1.\n",
    "})\n",
    "rewards.append({\n",
    "    'destroyed': -10.,\n",
    "    'stuck': -15.,\n",
    "    'reached': 10.,\n",
    "    'standard': -1.\n",
    "})\n",
    "\n",
    "\n",
    "sys.path.append('/home/naski/Documents/dev/maze_drone_v02')\n",
    "import gym_maze # Esta linha precisa estar ap√≥s o PATH\n",
    "\n",
    "# Importing custom environment\n",
    "env_name = 'maze-v0'\n",
    "env = suite_gym.load(env_name)\n",
    "\n",
    "# Testing\n",
    "env.reset()\n",
    "\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "# Converts environments, originally in pure Python, to tensors (using a wrapper)\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CREATING/RESETING THE AGENT\n",
    "agent = build_agent(fc_layer_params, env, learning_rate, train_env)\n",
    "agent.initialize()\n",
    "\n",
    "# GENERATE TRAINING SESSION\n",
    "session = TrainingSession(description, maze_size, env_name, rewards[0], agent, collect_steps_per_iteration, \n",
    "                        1, eval_interval, replay_buffer_max_length, num_eval_episodes)\n",
    "\n",
    "# TRAINING\n",
    "step_log, returns, finished, crashed, stucked, steped, _, replay_buffer, _ = session.train()\n",
    "\n",
    "# CLEAR MEMORY\n",
    "del(session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 1 - 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================== Loading Checkpoint:\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=10400>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=10400>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================================== Loading Checkpoint:\")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "checkpoint_dir = './checkpoint/phase-2-2-stuck'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_dir,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=agent.train_step_counter\n",
    ")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "    \n",
    "print(agent.train_step_counter)\n",
    "\n",
    "agent._optimizer.learning_rate = learning_rate\n",
    "print(agent._optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources import compute_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================== Testing:\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -11.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 0\n",
      "Maze site set: 3x3\n",
      "-1.714 0.844 17 3 10.815\n"
     ]
    }
   ],
   "source": [
    "print(\"========================================================================== Testing:\")\n",
    "\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "eval_py_env.update_rewards(rewards[1]['destroyed'], rewards[1]['stuck'], rewards[1]['reached'], rewards[1]['standard'])\n",
    "eval_py_env.set_mode(0) # walls\n",
    "eval_py_env.set_size(maze_size)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps = compute_logs(eval_env, agent.policy, rewards[1], 1000)\n",
    "\n",
    "print(avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 2 - 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================== Loading Checkpoint:\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=10400>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=19400>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=19400>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================================== Loading Checkpoint:\")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "checkpoint_dir = './checkpoint/phase-2-3-stuck'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_dir,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=agent.train_step_counter\n",
    ")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "    \n",
    "print(agent.train_step_counter)\n",
    "\n",
    "agent._optimizer.learning_rate = learning_rate\n",
    "print(agent._optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================== Testing:\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -15.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 0\n",
      "Maze site set: 3x3\n",
      "-2.28 0.885 296 0 8.861\n"
     ]
    }
   ],
   "source": [
    "print(\"========================================================================== Testing:\")\n",
    "\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "eval_py_env.update_rewards(rewards[2]['destroyed'], rewards[2]['stuck'], rewards[2]['reached'], rewards[2]['standard'])\n",
    "eval_py_env.set_mode(0) # walls\n",
    "eval_py_env.set_size(maze_size)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps = compute_logs(eval_env, agent.policy, rewards[1], 1000)\n",
    "\n",
    "print(avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 3 - 3001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================== Loading Checkpoint:\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=19400>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7900>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7900>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================================== Loading Checkpoint:\")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "checkpoint_dir = './checkpoint/phase-2-4-stuck'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_dir,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=agent.train_step_counter\n",
    ")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "    \n",
    "print(agent.train_step_counter)\n",
    "\n",
    "agent._optimizer.learning_rate = learning_rate\n",
    "print(agent._optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================== Testing:\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -11.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 0\n",
      "Maze site set: 3x3\n",
      "-1.192 0.872 34 118 9.298\n"
     ]
    }
   ],
   "source": [
    "print(\"========================================================================== Testing:\")\n",
    "\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "eval_py_env.update_rewards(rewards[1]['destroyed'], rewards[1]['stuck'], rewards[1]['reached'], rewards[1]['standard'])\n",
    "eval_py_env.set_mode(0) # walls\n",
    "eval_py_env.set_size(maze_size)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps = compute_logs(eval_env, agent.policy, rewards[1], 1000)\n",
    "\n",
    "print(avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 4 - 3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================== Loading Checkpoint:\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7900>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=12500>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=12500>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================================== Loading Checkpoint:\")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "checkpoint_dir = './checkpoint/phase-2-5-stuck'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_dir,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=agent.train_step_counter\n",
    ")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "    \n",
    "print(agent.train_step_counter)\n",
    "\n",
    "agent._optimizer.learning_rate = learning_rate\n",
    "print(agent._optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================== Testing:\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -15.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 0\n",
      "Maze site set: 3x3\n",
      "-3.345 0.879 148 0 9.036\n"
     ]
    }
   ],
   "source": [
    "print(\"========================================================================== Testing:\")\n",
    "\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "eval_py_env.update_rewards(rewards[2]['destroyed'], rewards[2]['stuck'], rewards[2]['reached'], rewards[2]['standard'])\n",
    "eval_py_env.set_mode(0) # walls\n",
    "eval_py_env.set_size(maze_size)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps = compute_logs(eval_env, agent.policy, rewards[1], 1000)\n",
    "\n",
    "print(avg_return, finished_percentage, crashes_counter, stuck_counter, avg_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-drone-v03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

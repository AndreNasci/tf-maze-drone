{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Espilon-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 20:31:14.505268: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 20:31:14.511717: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 20:31:14.610321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 20:31:16.042952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "\n",
    "from resources import build_agent, TrainingSession\n",
    "import pandas as pd\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "start_epsilon = 0.8\n",
    "n_of_steps = 10_000\n",
    "end_epsilon = 0.0001\n",
    "epsilon = tf.compat.v1.train.polynomial_decay(\n",
    "    start_epsilon,\n",
    "    global_step,\n",
    "    n_of_steps,\n",
    "    end_learning_rate=end_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 1\n",
      "Mode set: 1\n",
      "Maze site set: 3x3\n",
      "Maze site set: 3x3\n",
      "WARNING:tensorflow:From /home/naski/Documents/dev/maze_drone_v02/maze-drone-v03/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "Rewards: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}\n",
      "WARNING:tensorflow:From /home/naski/Documents/dev/maze_drone_v02/maze-drone-v03/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "============================================================== After first training:\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3500>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3500>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "# if len(sys.argv) != 4:\n",
    "#     print(\"Usage: X Y Z -> X = Combination | Y = Min and Max Run | Z = Learning Rate\")\n",
    "#     return -1\n",
    "\n",
    "# min_combination = int(sys.argv[1])\n",
    "# min_run = int(sys.argv[2])\n",
    "# max_run = min_run\n",
    "# learning_rate = int(sys.argv[3])\n",
    "\n",
    "min_combination = 3\n",
    "min_run = 1\n",
    "max_run = min_run\n",
    "\n",
    "\n",
    "\n",
    "num_iterations = 10_000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 64  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "#replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 100  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 100  # @param {type:\"integer\"}\n",
    "\n",
    "# Agent fully connected layer params \n",
    "fc_layer_params = (200,) \n",
    "\n",
    "# File's name\n",
    "description = \"24\"\n",
    "\n",
    "maze_size = 3\n",
    "\n",
    "rewards = []\n",
    "rewards.append({\n",
    "    'destroyed': -10.,\n",
    "    'stuck': - 6.,\n",
    "    'reached': 10.,\n",
    "    'standard': -1.\n",
    "})\n",
    "rewards.append({\n",
    "    'destroyed': -10.,\n",
    "    'stuck': -11.,\n",
    "    'reached': 10.,\n",
    "    'standard': -1.\n",
    "})\n",
    "rewards.append({\n",
    "    'destroyed': -10.,\n",
    "    'stuck': -15.,\n",
    "    'reached': 10.,\n",
    "    'standard': -1.\n",
    "})\n",
    "\n",
    "\n",
    "sys.path.append('/home/naski/Documents/dev/maze_drone_v02')\n",
    "import gym_maze # Esta linha precisa estar ap√≥s o PATH\n",
    "\n",
    "# Importing custom environment\n",
    "env_name = 'maze-v0'\n",
    "env = suite_gym.load(env_name)\n",
    "\n",
    "# Testing\n",
    "env.reset()\n",
    "\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "# Converts environments, originally in pure Python, to tensors (using a wrapper)\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CREATING/RESETING THE AGENT\n",
    "agent = build_agent(fc_layer_params, env, learning_rate, train_env)\n",
    "agent.initialize()\n",
    "\n",
    "# GENERATE TRAINING SESSION\n",
    "session = TrainingSession(description, maze_size, env_name, rewards[0], agent, collect_steps_per_iteration, \n",
    "                        1, eval_interval, replay_buffer_max_length, num_eval_episodes)\n",
    "\n",
    "# TRAINING\n",
    "step_log, returns, finished, crashed, stucked, steped, _, replay_buffer, _ = session.train()\n",
    "\n",
    "# CLEAR MEMORY\n",
    "del(session)\n",
    "\n",
    "\n",
    "\n",
    "print(\"============================================================== After first training:\")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "checkpoint_dir = './checkpoint/phase-2-stuck'\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=checkpoint_dir,\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=agent.train_step_counter\n",
    ")\n",
    "\n",
    "print(agent.train_step_counter)\n",
    "\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "    \n",
    "print(agent.train_step_counter)\n",
    "\n",
    "agent._optimizer.learning_rate = learning_rate\n",
    "print(agent._optimizer.learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(agent._epsilon_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._epsilon_greedy = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<tensorflow.python.keras.optimizer_v2.learning_rate_schedule.PolynomialDecay object at 0x75b760042080>, <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "print(agent._epsilon_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================== Training:\n",
      "Combination 3  | Run 1\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3500>\n",
      "functools.partial(<tensorflow.python.keras.optimizer_v2.learning_rate_schedule.PolynomialDecay object at 0x75b760042080>, <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=0>)\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -15.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Rewards Updated: {'destroyed': -10.0, 'stuck': -15.0, 'reached': 10.0, 'standard': -1.0}\n",
      "Mode set: 0\n",
      "Mode set: 0\n",
      "Maze site set: 3x3\n",
      "Maze site set: 3x3\n",
      "Rewards: {'destroyed': -10.0, 'stuck': -15.0, 'reached': 10.0, 'standard': -1.0}\n",
      "step = 4000\n",
      "step = 5000\n",
      "step = 6000\n",
      "step = 7000\n",
      "step = 8000\n",
      "step = 9000\n",
      "step = 10000\n",
      "step = 11000\n",
      "step = 12000\n",
      "step = 13000\n",
      "learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n"
     ]
    }
   ],
   "source": [
    "print(\"========================================================================== Training:\")\n",
    "\n",
    "\n",
    "for combination in range(min_combination-1, min_combination):\n",
    "\n",
    "    for run in range(min_run-1, max_run):\n",
    "        print('Combination', combination + 1, ' | Run', run + 1)\n",
    "        train_checkpointer = common.Checkpointer(\n",
    "            ckpt_dir=checkpoint_dir,\n",
    "            max_to_keep=1,\n",
    "            agent=agent,\n",
    "            policy=agent.policy,\n",
    "            replay_buffer=replay_buffer,\n",
    "            global_step=agent.train_step_counter\n",
    "        )\n",
    "        agent._optimizer.learning_rate = learning_rate\n",
    "        print(agent.train_step_counter)\n",
    "        agent._epsilon_greedy = epsilon\n",
    "        print(agent._epsilon_greedy)\n",
    "\n",
    "        # GENERATE TRAINING SESSION\n",
    "        session = TrainingSession(description, maze_size, env_name, rewards[combination], agent, collect_steps_per_iteration, \n",
    "                                num_iterations, eval_interval, replay_buffer_max_length, num_eval_episodes)\n",
    "        \n",
    "        # TRAINING\n",
    "        step_log, returns, finished, crashed, stucked, steped, log_loss, _, _ = session.train(without_wall_training=False)\n",
    "\n",
    "        # LOGGING\n",
    "        df_log = pd.DataFrame({'Step': step_log, 'Average Return': returns, '% Finished': finished, 'Crash Counter': crashed, 'Stuck Counter': stucked, 'Avg Steps/Episode': steped, 'Loss log': log_loss})\n",
    "        df_log.to_csv(f\"logs/03-walls/{description}_comb-{combination+1}-run-{run+1}.csv\", index=None, header=True)\n",
    "\n",
    "        # CLEAR MEMORY\n",
    "        #del(agent)\n",
    "        del(session)\n",
    "        del(df_log)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-drone-v03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

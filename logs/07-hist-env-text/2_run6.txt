Combination: 1
Gamma: 1
Epsilon: 2
Buffer: 0
LR: 0

========================================================================== Training PHASE 1:
Rewards: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}
Size: 3
Mode: 1
Hist env: 3
step = 1000
learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>

========================================================================== Training PHASE 2:
Rewards: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}
Size: 3
Mode: 0
Hist env: 3
step = 2000
step = 3000
step = 4000
step = 5000
step = 6000
learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>

========================================================================== Training PHASE 3:
Rewards: {'destroyed': -10.0, 'stuck': -11.0, 'reached': 10.0, 'standard': -1.0}
Size: 3
Mode: 0
Hist env: 3
step = 7000
step = 8000
step = 9000

=============================================================( EARLY STOP )
Big check log:
Avg return: 2.52
Finished: 0.91
Crash Counter: 0
Stuck counter: 2
Early stop at 9900
==========================================================================

learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>
Fase 1 terminada em 1000
Fase 2 terminada em 6900


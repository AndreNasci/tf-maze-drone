Combination: 2
Gamma: 0
Epsilon: 2
Buffer: 2
LR: 0

========================================================================== Training PHASE 1:
Rewards: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}
Size: 3
Mode: 1
Hist env: 3
step = 1000
step = 2000
learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>

========================================================================== Training PHASE 2:
Rewards: {'destroyed': -10.0, 'stuck': -6.0, 'reached': 10.0, 'standard': -1.0}
Size: 3
Mode: 0
Hist env: 3
step = 3000
step = 4000
step = 5000
learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>

========================================================================== Training PHASE 3:
Rewards: {'destroyed': -10.0, 'stuck': -15.0, 'reached': 10.0, 'standard': -1.0}
Size: 3
Mode: 0
Hist env: 3
step = 6000
step = 7000
step = 8000
step = 9000
step = 10000
step = 11000
step = 12000
step = 13000
step = 14000
step = 15000
learning_rate inside: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>
Fase 1 terminada em 2300
Fase 2 terminada em 5100

